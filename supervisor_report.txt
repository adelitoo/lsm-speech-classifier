### **Project Summary: Improving Speech Recognition Accuracy by Optimizing the Audio Front-End**

**1. Initial Situation**

Initially, your project was designed to classify spoken words using a Spiking Neural Network (a Liquid State Machine). The existing pipeline took raw audio files, converted them into Mel spectrograms with a fixed number of 200 frequency bands (Mels), and then transformed these spectrograms into spike trains for the neural network to process. The baseline accuracy of this system was **52.62%**.

**2. Supervisor's Advice & Our Goal**

Your supervisor advised that the initial audio processing step‚Äîthe filterbank‚Äîis critical for performance. The key recommendations were:
*   Use a bio-inspired filterbank that mimics the human cochlea, such as **Mel-scaled triangular filters** or **Gammatone filters**.
*   Clarify that the goal is to imitate the cochlea, not just uniformly divide the spectrum.
*   The **width and position of the frequency bands should be determined experimentally** to find the optimal configuration.

Our goal was to implement this advice to improve the model's accuracy.

**3. What We Did: A Systematic Approach to Experimentation**

We followed a structured plan to explore the impact of the filterbank on performance.

*   **Code Parameterization:** Our first step was to make your code more flexible for experimentation. We modified the `spect_to_spike_train.py` script so that you could easily change the type of filterbank (`mel` or `gammatone`) and the number of frequency channels (e.g., 128, 192, 256) using command-line arguments. This was crucial for efficiently testing different configurations.

*   **Gammatone Filterbank Implementation:** We integrated a new audio processing option by adding a function that uses a **Gammatone filterbank**. This directly addressed your supervisor's advice to explore it as a highly bio-plausible alternative to the Mel filterbank. We also added a small epsilon value to the logarithm calculation to prevent "divide by zero" warnings and ensure numerical stability.

*   **Controlled Experiments:** With the flexible code in place, we ran a series of controlled experiments to systematically measure the impact of our changes. We tested the following configurations, running the full pipeline for each and recording the final accuracy:
    *   **Baseline:** 200 Mel filters
    *   **Experiment A:** 128 Mel filters
    *   **Experiment B:** 256 Mel filters
    *   **Experiment C:** 128 Gammatone filters
    *   **Experiment D:** 192 Gammatone filters
    *   **Experiment E:** 256 Gammatone filters

**4. Results & Key Findings**

The experiments yielded very clear and insightful results:

| Filterbank | Number of Filters | Accuracy |
| :--- | :--- | :--- |
| Mel | 128 | 52.58% |
| Mel | 200 (Baseline) | 52.62% |
| Mel | 256 | 50.92% |
| **Gammatone** | **128** | **54.37%** üèÜ |
| Gammatone | 192 | 53.92% |
| Gammatone | 256 | 53.25% |

Our key findings were:
*   The **Gammatone filterbank consistently outperformed the Mel filterbank**.
*   The best-performing configuration was the **128-channel Gammatone filterbank**, which achieved an accuracy of **54.37%**‚Äîa significant improvement over the baseline.
*   For both filter types, we observed that **more filters are not always better**. Performance decreased when the number of channels was too high, indicating that there is an optimal "sweet spot" for feature dimensionality at this stage.

**5. Final Outcome**

By following your supervisor's advice to experiment with different bio-inspired filterbanks, we successfully improved the model's classification accuracy. We have now updated the project's default configuration to use the 128-channel Gammatone filterbank, ensuring that the best-performing setup is used for all future work.

---

### **6. Technical Background: Filterbanks, Mel Spectrograms, and Gammatone Filters**

To understand the work we did, it's helpful to clarify the key signal processing concepts involved.

**What is a Filterbank?**

Think of a filterbank like a prism for sound. A prism takes white light and splits it into its constituent colors (a spectrum). Similarly, an audio filterbank takes a complex sound signal (like speech) and splits it into different frequency bands, from low pitches to high pitches.

Each "filter" in the bank is a **band-pass filter**, meaning it only allows a specific, narrow range of frequencies to pass through while blocking others. By using many of these filters in parallel, we can analyze how much energy or "loudness" is present in each frequency band of the audio signal at any given moment. This is the first and most critical step in getting a computer to "understand" the content of an audio file.

**What is a Spectrogram?**

A spectrogram is a way to visualize the output of a filterbank. It's a graph that shows how the frequency content of a signal changes over time.
*   **Time** is on the horizontal axis (x-axis).
*   **Frequency** (pitch) is on the vertical axis (y-axis).
*   The **Amplitude** (loudness) of a specific frequency at a specific time is represented by color or intensity. Brighter colors mean that frequency is louder at that moment.

This visual representation is what our system uses to "see" the audio data.

**What is a Mel Spectrogram? (Your Original Approach)**

A Mel spectrogram is a special kind of spectrogram that is **bio-inspired**, meaning it's designed to mimic how humans perceive sound. It does this by using the **Mel scale**.

The Mel scale is a perceptual scale of pitches. Humans are much better at distinguishing small differences between low frequencies (e.g., 100 Hz vs 200 Hz) than they are at distinguishing small differences between high frequencies (e.g., 7000 Hz vs 7100 Hz). The Mel scale reflects this: it has more space between filters at lower frequencies and packs them more tightly at higher frequencies.

The filterbank for a Mel spectrogram uses simple, overlapping **triangular filters** spaced according to this Mel scale. This was the approach your project was originally using.

**What are Gammatone Filters? (Our New, Better Approach)**

Gammatone filters are another, more advanced bio-inspired model of the human auditory system. They are considered a more accurate representation of the filtering that happens in the **cochlea** (the spiral-shaped cavity of the inner ear).

The key difference is the shape of the filters. Instead of simple triangular filters, Gammatone filters have a more complex, rounded shape that is derived from a gamma function multiplied by a sine wave. This shape more closely matches the response of the auditory nerve fibers in the ear.

By using Gammatone filters, we are creating a representation of the sound that is, in theory, closer to what the human brain actually receives. Our experiments showed that this more detailed and biologically faithful representation allowed the Spiking Neural Network to extract more meaningful features, leading to a higher classification accuracy.